{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18df2de-e889-4c79-b0d3-1512beeccbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1fd0fc-fa37-44ce-b42f-4db8dd10e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_coordinates_file = open('coordinates.txt', 'r')\n",
    "sources_coordinates_lines = sources_coordinates_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7138dcc-4c47-474b-98f6-ec84185280aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_lines = []\n",
    "for line in sources_coordinates_lines:\n",
    "    integers = [str(int(float(num))) for num in line.split(\",\")]\n",
    "    converted_lines.append(\", \".join(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c83bcc2-8624-45a3-ac75-ba85c636842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_TRAINING_SET = 3400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ff1497-7f85-4cdd-8274-0b1c7e59adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data_path = '/Users/antonyzappacosta/Desktop/gamma_sources_identification/CNN_project/dataset'\n",
    "# ASSUMING WE ARE DOING BINARY CLASSIFICATION\n",
    "def load_data():\n",
    "    # let's put directly images inside these arrays and not only image paths\n",
    "    x_train = []\n",
    "    y_train_loc = []\n",
    "    x_test = []\n",
    "    y_test_loc = []\n",
    "\n",
    "    train_bkg_count = 0\n",
    "    train_src_count = 0\n",
    "\n",
    "    for img_name in os.listdir(data_path):\n",
    "        img_full_path = data_path + '/' + img_name\n",
    "        #print(img_full_path)\n",
    "        image = cv2.imread(img_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.pyrDown(image)\n",
    "        image = cv2.pyrDown(image)\n",
    "        image = cv2.pyrDown(image)\n",
    "        img_index = int(re.findall('\\d+', img_name )[0])\n",
    "        source_x = int(converted_lines[img_index].split(\",\")[1])\n",
    "        source_y = int(converted_lines[img_index].split(\",\")[2])\n",
    "        source_coordinates = (source_x, source_y)\n",
    "        \n",
    "        if train_src_count < NUM_IMAGES_TRAINING_SET:\n",
    "            x_train.append(image)\n",
    "            y_train_loc.append(source_coordinates)\n",
    "            train_src_count += 1\n",
    "        else: # append in test set\n",
    "            x_test.append(image)\n",
    "            y_test_loc.append(source_coordinates)\n",
    "            train_src_count += 1\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train_loc = np.array(y_train_loc)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test_loc = np.array(y_test_loc)\n",
    "    \n",
    "    #return (x_train, y_train), (x_test, y_test)\n",
    "    return (x_train, y_train_loc), (x_test, y_test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f43b07-d015-4a4d-b4a9-3cfcd4bbe68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = load_data()\n",
    "(x_train, y_train_loc), (x_test, y_test_loc) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b0c639-effd-4af4-bf37-cbf5c135ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 63, 63)\n",
      "(3400, 2)\n",
      "(600, 63, 63)\n",
      "(600, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_loc = y_train_loc / 8\n",
    "y_test_loc = y_test_loc / 8\n",
    "print(x_train.shape)\n",
    "print(y_train_loc.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeb4d4f-7771-462f-bd20-f03b057c560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.75  28.75 ]\n",
      " [19.    26.75 ]\n",
      " [48.625 30.375]\n",
      " ...\n",
      " [43.5   15.125]\n",
      " [44.    17.75 ]\n",
      " [21.875 47.125]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf147d8-045d-4a2b-ad4e-9c65bcba3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "56353583-b236-4af9-955e-25f82e376a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define the input shape based on your image size\n",
    "input_shape = (63, 63, 1)\n",
    "\n",
    "# Define the model architecture with regularization\n",
    "def create_model():\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Convolutional layers with L2 regularization\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "    maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01))(maxpool1)\n",
    "    maxpool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    # Flatten layer\n",
    "    flatten = Flatten()(maxpool2)\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    dense1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten)\n",
    "    dropout1 = Dropout(0.5)(dense1)  # Dropout layer with 50% dropout rate\n",
    "\n",
    "    # Add an additional dense layer with dropout\n",
    "    dense2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(dropout1)\n",
    "    dropout2 = Dropout(0.5)(dense2)  # Dropout layer with 50% dropout rate\n",
    "    \n",
    "    output_layer = Dense(2)(dropout2)  # Output layer with 2 neurons for x and y coordinates\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15975f9-bdc5-49b5-ab3d-58560d88fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 16:01:17.745381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "################## LOADING THE MODEL ####################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model=load_model('gamma_conv_model_0209-00e31.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b8e94732-062d-4534-855d-3de379fd30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model = create_model()\n",
    "\n",
    "# Create EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=7,          # Number of epochs with no improvement to wait before stopping\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08224a98-734e-487c-b3d6-b41901f69731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model using data augmentation\n",
    "batch_size = 32\n",
    "epochs = 5000\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train_loc,\n",
    "    validation_split=0.1,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa2e242a-1046-4a84-9f16-08f732449398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Assuming you have the model predictions for a test image\n",
    "test_image_index = 223# Change this to the index of the test image you want to visualize\n",
    "test_image = x_test[test_image_index]\n",
    "coord_predictions = model.predict(np.expand_dims(test_image, axis=0))\n",
    "\n",
    "\n",
    "# Extract predicted coordinates\n",
    "predicted_coords = coord_predictions[0]\n",
    "predicted_coords[0] = predicted_coords[0]\n",
    "predicted_coords[1] = predicted_coords[1]\n",
    "#print(coord_predictions)\n",
    "\n",
    "# Display the test image\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Add bounding box if source is predicted\n",
    "\n",
    "x, y = predicted_coords  # Adjust coordinates according to your format\n",
    "width = height = 10  # Adjust these values according to your desired box size\n",
    "rect = patches.Rectangle((x - width/2, y - height/2), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9afc664-b758-4082-aff9-80f3db45de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cta_simulation/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('gamma_conv_model_0209-00e31.h5')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac519df6-b229-427b-81bd-82e4b8e93c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "model.save('gamma_conv_model_0209-00e31.keras')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec94466-5f49-4776-92cf-42ed15aea361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
