{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4548ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a14b7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/var/tmp/zapp_an-a/Desktop/gamma_sources_identification/Full dataset/gray_stretch_dataset'\n",
    "# ASSUMING WE ARE DOING BINARY CLASSIFICATION\n",
    "def load_data():\n",
    "    # let's put directly images inside these arrays and not only image paths\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "\n",
    "    train_bkg_count = 0\n",
    "    train_src_count = 0\n",
    "\n",
    "    for img_name in os.listdir(data_path):\n",
    "        img_full_path = data_path + '/' + img_name\n",
    "        image = cv2.imread(img_full_path)\n",
    "        image = cv2.pyrDown(image)\n",
    "        image = cv2.pyrDown(image)\n",
    "        if img_name[0] == 'B': #background image\n",
    "            if train_bkg_count < 800: # append in training set\n",
    "                x_train.append(image)\n",
    "                y_train.append(0)\n",
    "                train_bkg_count += 1\n",
    "            else: # append in test set\n",
    "                x_test.append(image)\n",
    "                y_test.append(0)\n",
    "        else: #source image\n",
    "            if train_src_count < 800:\n",
    "                x_train.append(image)\n",
    "                y_train.append(1)\n",
    "                train_src_count += 1\n",
    "            else: # append in test set\n",
    "                x_test.append(image)\n",
    "                y_test.append(1)\n",
    "\n",
    "    # at the end of the for loop we should have the split dataset\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e10d283-930b-4de8-ae69-d15f0c30054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b6b581c-a70d-47ae-8706-d3d137677880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 150, 150, 3)\n",
      "(1600,)\n",
      "(400, 150, 150, 3)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34afee-2c39-42b1-886a-78da2b55fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so we have the whole loaded dataset. Each image is of course made of 3 channels. Let's see how a\n",
    "# possible CNN behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a350db1-8986-4619-be7c-674d6380e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68a6267a-e319-4754-bfe7-0d076a313f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILING THE CONVOLUTIONAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45b8c75-3f24-4751-b664-975e6435c92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:34:48.964520: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-24 09:34:48.981827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-24 09:34:49.110028: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-24 09:34:49.110912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 09:34:49.629086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "04528ee4-3902-4c0a-878e-76ddd73c9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 2\n",
    "\n",
    "model = keras.Sequential()\n",
    "#before we included all the layers in the \"constructor of Sequential\", but we can also do model.add\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3))) # the input shape only in the first layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5)) #just to fight overfitting, we drop some (neurons?)\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')) #sigmoid because we're doing binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d1d74d7-ac0d-4665-88f7-cf38bb5659f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "98daf769-09d9-48b8-99d4-3e44984d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1472 - acc: 0.9361 - val_loss: 0.4684 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 0.1460 - acc: 0.9306 - val_loss: 0.8949 - val_acc: 0.6500\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.1370 - acc: 0.9375 - val_loss: 0.7643 - val_acc: 0.6812\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1241 - acc: 0.9451 - val_loss: 0.6896 - val_acc: 0.7250\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1153 - acc: 0.9486 - val_loss: 0.5274 - val_acc: 0.8313\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 0.1300 - acc: 0.9444 - val_loss: 0.4900 - val_acc: 0.7750\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.1240 - acc: 0.9417 - val_loss: 0.7785 - val_acc: 0.7125\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1170 - acc: 0.9521 - val_loss: 1.3665 - val_acc: 0.6187\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 0.1364 - acc: 0.9333 - val_loss: 0.8219 - val_acc: 0.7375\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1106 - acc: 0.9493 - val_loss: 0.3564 - val_acc: 0.8375\n"
     ]
    }
   ],
   "source": [
    "# training the neural network\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10)\n",
    "#few epochs for avoiding overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "237f7450-2c10-4dc7-9ea0-b6815c418a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 39ms/step - loss: 0.7437 - acc: 0.8550\n",
      "Test Accuracy = 0.8550000190734863\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928e03-c7be-456c-a8ac-5e15c1d586dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
